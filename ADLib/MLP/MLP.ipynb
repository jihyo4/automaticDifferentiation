{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8510d899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/awid/automaticDifferentiation/ADLib`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.precompile()\n",
    "Pkg.activate(\"..\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ee995d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADLib.DataLoader{Tuple{LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, BitMatrix}}((Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[1 1 … 0 0]), 64, true, [[934, 4107, 3341, 7747, 411, 510, 6033, 3430, 3043, 1638  …  1793, 7315, 4230, 6973, 3265, 2132, 533, 3493, 1276, 3606], [2905, 40, 6860, 2297, 1326, 4580, 5633, 2521, 5752, 5608  …  1294, 7973, 5331, 876, 3305, 5780, 3258, 7565, 6957, 2047], [6255, 6040, 3961, 971, 3220, 6385, 792, 857, 1410, 6921  …  211, 7435, 5280, 3686, 3893, 82, 7919, 3264, 6903, 4411], [5059, 6285, 6000, 34, 7230, 7134, 7768, 7634, 7547, 111  …  772, 4009, 6242, 3347, 2743, 3610, 1700, 1369, 3377, 239], [3671, 3199, 3107, 4209, 4240, 3443, 7555, 3419, 5955, 5689  …  6116, 5975, 1750, 5169, 3019, 6120, 3057, 4592, 5916, 1764], [215, 3163, 2296, 7511, 6684, 3251, 2165, 4479, 3221, 6156  …  1667, 2526, 1533, 6449, 1690, 4604, 568, 5007, 2040, 416], [3704, 4566, 1205, 3170, 5602, 4681, 2896, 6577, 7047, 2579  …  4505, 928, 2411, 4820, 6556, 2826, 1243, 3338, 3502, 3765], [6216, 6283, 7853, 4586, 281, 5476, 6753, 3807, 381, 2959  …  3063, 2485, 5226, 2117, 5197, 3512, 5259, 6763, 3645, 1080], [7421, 5751, 2980, 3616, 2030, 2756, 4011, 2645, 6869, 3695  …  5168, 570, 2925, 1086, 6351, 615, 7079, 6616, 3148, 4420], [7009, 4444, 1430, 2740, 4028, 1554, 7725, 89, 7396, 2611  …  5966, 33, 1926, 6551, 4545, 5754, 5042, 794, 3460, 5876]  …  [4797, 4914, 7922, 4393, 3647, 4141, 5276, 4534, 4757, 4481  …  1704, 4883, 6971, 3285, 2976, 1829, 1905, 2369, 1076, 3176], [261, 6186, 4329, 4164, 1481, 7606, 1022, 1443, 653, 2058  …  7810, 7123, 2051, 4878, 654, 1311, 1486, 7062, 1514, 342], [6278, 2633, 5172, 180, 4285, 3114, 3423, 6084, 5452, 1436  …  4201, 6987, 6087, 3330, 3858, 5697, 2528, 3007, 3295, 22], [2183, 7950, 3707, 1029, 3739, 4744, 610, 4554, 2269, 7338  …  2366, 6224, 6412, 2667, 4519, 624, 97, 7162, 6230, 543], [5796, 5130, 1463, 7996, 1992, 1146, 1168, 7803, 957, 5699  …  3492, 977, 7084, 1614, 1265, 7912, 4390, 264, 2834, 5761], [405, 3563, 4185, 6168, 6836, 6472, 3508, 1435, 5075, 2884  …  5046, 5098, 4645, 839, 4794, 1344, 6473, 6051, 2670, 7314], [6790, 5529, 2055, 7746, 1089, 3768, 6274, 3020, 2328, 887  …  4514, 1563, 5911, 6313, 744, 521, 7841, 1202, 3997, 748], [4105, 1158, 646, 4199, 7837, 7296, 6429, 4062, 2506, 5358  …  2128, 6349, 3100, 4887, 4860, 7660, 7786, 1640, 6432, 6097], [5071, 3309, 789, 4256, 474, 3319, 5844, 5082, 5383, 7498  …  3259, 6147, 5038, 3137, 6691, 4395, 4621, 2442, 4431, 609], [3582, 4374, 5096, 4417, 3918, 798, 4882, 369, 4600, 7823  …  6297, 4759, 2125, 2102, 1475, 1722, 1473, 2466, 1952, 1358]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JLD2\n",
    "X_train = load(\"./imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"./imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "X_test = load(\"./imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"./imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "nothing\n",
    "using ADLib\n",
    "\n",
    "batch_size=64\n",
    "dataset = ADLib.DataLoader((X_train, y_train), batchsize=batch_size, shuffle=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b80113e-47b6-4b6c-994b-9e1ef713075d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (7.23s) \tTrain: (l: 0.52, a: 0.76) \tTest: (l: 0.39, a: 0.84)\n",
      "Epoch: 2 (3.18s) \tTrain: (l: 0.09, a: 0.97) \tTest: (l: 0.52, a: 0.82)\n",
      "Epoch: 3 (3.21s) \tTrain: (l: 0.05, a: 0.98) \tTest: (l: 0.75, a: 0.81)\n",
      "Epoch: 4 (3.58s) \tTrain: (l: 0.02, a: 0.99) \tTest: (l: 1.05, a: 0.80)\n",
      "Epoch: 5 (3.17s) \tTrain: (l: 0.03, a: 0.99) \tTest: (l: 0.93, a: 0.83)\n"
     ]
    }
   ],
   "source": [
    "using Printf\n",
    "\n",
    "model = ADLib.Sequence(\n",
    "    ADLib.Dense{Float64}(ADLib.ReLU(), size(X_train, 1), 32),\n",
    "    ADLib.Dense{Float64}(ADLib.Sigmoid(), 32, 1)\n",
    ")\n",
    "epochs = 5\n",
    "for epoch in 1:epochs\n",
    "    t_loss = 0.0\n",
    "    t_accuracy = 0.0\n",
    "    gradient = zeros(Float64, 1, 64)\n",
    "    num_samples = 0\n",
    "    opt = ADLib.Adam()\n",
    "    t = @elapsed begin\n",
    "        for (x, y) in dataset\n",
    "            output = model(x)\n",
    "            t_loss += ADLib.binary_crossentropy(y, output)\n",
    "            t_accuracy += ADLib.binary_accuracy(y, output)\n",
    "            #println(size(y))\n",
    "            gradient = ADLib.binary_crossentropy_gradient(y, output) ./ batch_size\n",
    "            ADLib.backward_pass(model, gradient)\n",
    "            num_samples += 1\n",
    "            ADLib.update_weights(model, opt)\n",
    "            #println(\"next loop\")\n",
    "        end   \n",
    "        \n",
    "        train_loss = t_loss / num_samples\n",
    "        train_acc = t_accuracy / num_samples\n",
    "\n",
    "        y = model(X_test)\n",
    "        test_loss = ADLib.binary_crossentropy(y_test, y)\n",
    "        test_acc = ADLib.binary_accuracy(y_test, y)\n",
    "    end\n",
    "            \n",
    "    println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.2f, a: %.2f) \\tTest: (l: %.2f, a: %.2f)\", \n",
    "        epoch, t, train_loss, train_acc, test_loss, test_acc))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e70240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (15.55s) \tTrain: (l: 0.64, a: 0.79) \tTest: (l: 0.58, a: 0.85)\n",
      "Epoch: 2 (2.33s) \tTrain: (l: 0.45, a: 0.91) \tTest: (l: 0.44, a: 0.86)\n",
      "Epoch: 3 (2.14s) \tTrain: (l: 0.29, a: 0.94) \tTest: (l: 0.36, a: 0.87)\n",
      "Epoch: 4 (2.37s) \tTrain: (l: 0.20, a: 0.96) \tTest: (l: 0.33, a: 0.87)\n",
      "Epoch: 5 (2.30s) \tTrain: (l: 0.14, a: 0.98) \tTest: (l: 0.32, a: 0.87)\n"
     ]
    }
   ],
   "source": [
    "using Flux, Printf, Statistics\n",
    "\n",
    "#dataset = Flux.DataLoader((X_train, y_train), batchsize=64, shuffle=true)\n",
    "\n",
    "model = Chain(\n",
    "    Dense(size(X_train, 1), 32, relu),\n",
    "    Dense(32, 1, sigmoid)\n",
    ")\n",
    "\n",
    "loss(m, x, y) = Flux.Losses.binarycrossentropy(m(x), y)\n",
    "accuracy(m, x, y) = mean((m(x) .> 0.5) .== (y .> 0.5))\n",
    "\n",
    "opt = Flux.setup(Adam(), model)\n",
    "epochs = 5\n",
    "for epoch in 1:epochs\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    t = @elapsed begin\n",
    "        for (x, y) in dataset\n",
    "            grads = Flux.gradient(model) do m\n",
    "                l = loss(m, x, y)\n",
    "                total_loss += l\n",
    "                total_acc += accuracy(m, x, y)\n",
    "                return l\n",
    "            end\n",
    "            Optimisers.update!(opt, model, grads[1])\n",
    "            num_samples += 1\n",
    "        end\n",
    "\n",
    "        train_loss = total_loss / num_samples\n",
    "        train_acc = total_acc / num_samples\n",
    "\n",
    "        test_acc = accuracy(model, X_test, y_test)\n",
    "        test_loss = loss(model, X_test, y_test)\n",
    "    end\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.2f, a: %.2f) \\tTest: (l: %.2f, a: %.2f)\", \n",
    "        epoch, t, train_loss, train_acc, test_loss, test_acc))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
